{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendador de libros basado en generos literarios\n",
    "\n",
    "### Autores: \n",
    "\n",
    "Julián Andrés Muñoz Montoya, julian.munozm@udea.edu.co\n",
    "\n",
    "Santiago Alexis Sánchez Zuleta, salexis.sanchez@udea.edu.co\n",
    "\n",
    "\n",
    "\n",
    "El siguiente recomendador de contenidos, hace recomendaciones basado en los géneros favoritos del usuario. Nuestro recomendador predice un mayor rating para aquellos libros que sean de un genero preferido por el usuario. En nuestra base de datos, los libros tienen tags, los cuales son análogos a los géneros.\n",
    "\n",
    "La construcción de este recomendador consta de 3 etapas. \n",
    "\n",
    "En la primera etapa aplicamos el algoritmo Alternating Least Squares (ALS), sobre la tabla de ratings, la cual es de la siguiente forma.\n",
    "\n",
    "| ID usuario    | ID Libro      | Rating|\n",
    "| ------------- |:-------------:| -----:|\n",
    "|      15       |    518285     |   4   |\n",
    "\n",
    "El libro con el ID 518285 podría ser el señor de los anillos, entonces veamos que libros le podemos recomendar al usuario 15.\n",
    "\n",
    "Al aplicar el algoritmo ALS, obtenemos la siguiente tabla.\n",
    "\n",
    "| ID usuario    | ID Libro      | Rating| Predicción |\n",
    "| ------------- |:-------------:|:-----:| ----------:|\n",
    "|    155884     |    518285     |   4   |    3.89    |\n",
    "\n",
    "Del algoritmo también podemos obtener las N recomendaciones top para cada usuario, por ejemplo con N = 3. Estas recomendaciones tienen un rating predecido por nuestro sistema.\n",
    "\n",
    "\n",
    "| ID usuario | ID Libro| Rating predecido|\n",
    "| -----      |  :-----:|         -------:|\n",
    "|         148|     1400|                5|\n",
    "|         148|       52|              4.6|\n",
    "|         148|     6634|              4.4|\n",
    "|         564|     1188|              4.2|\n",
    "|         564|     6546|              3.6|\n",
    "|         564|       39|              3.4|\n",
    "\n",
    "En la segunda etapa tomamos estas recomendaciones y ejecutamos el siguiente proceso: \n",
    "\n",
    "1. Tomamos las N recomendaciones para el usuario i.\n",
    "2. Extraemos los tags de estos libros.\n",
    "3. Agrupamos los libros por tags y sacamos el promedio para los K tags preferidos por usuario.\n",
    "4. Ordenamos los K tags preferidos por el usuario por su rating promedio, este rating promedio, será el rating de cada tag.\n",
    "5. Tomamos nuevamente las N recomendaciones para el usuario i y al rating de cada libro j con el tag k, le sumamos el rating del usuario i para el tag k.\n",
    "\n",
    "Sea i un usuario, j un libro recomendado al usuario i y k el tag del libro j.\n",
    "\n",
    "* rating_pesado = rating_predecido(i, j) + tag_rating(i, k)\n",
    "\n",
    "Nuevamente tenemos una tabla con usuarios, libros y ratings pesados.\n",
    "\n",
    "| ID usuario | ID Libro| Rating pesado   |\n",
    "| -----      |  :-----:|         -------:|\n",
    "|         321|     1400|                5|\n",
    "|         564|     6546|              4.8|\n",
    "|         564|     1188|              4.5|\n",
    "|         654|     1188|              4.9|\n",
    "\n",
    "Note que en la tabla anterior a esta, para el usuario 564, el rating del libro 6546 era menor que el rating de este usuario para el libro 1188, sin embargo con nuestro rating pesado, el libro 6564 tiene mas peso que el libro 1188.\n",
    "\n",
    "Finalmente en la tercera etapa aplicamos el algoritmo ALS sobre nuestros ratings pesados.\n",
    "\n",
    "| ID usuario    | ID Libro      | Rating predecido |\n",
    "| ------------- |:-------------:|            -----:|\n",
    "|      15       |    418589     |            4.6   |\n",
    "\n",
    "En este caso el libro 418589 es Juego de tronos de la serie de novelas canción de hielo y fuego es nuestra mejor recomendación para el usuario 15, el genero de este libro es alta fantasia al igual que El señor de los anillos, el cual tenia el mayor rating para el usuario 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField}\n",
    "import org.apache.spark.sql.functions.{desc, mean, col}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.ml.recommendation.{ALS, ALSModel}\n",
    "import org.apache.spark.sql.types.IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Nuestro dataset goodbooks-10k contiene 10.000 libros con un millón de ratings.\n",
    "\n",
    "En la etapa uno utilizamos la tabla ratings, en la etapa 2, las tablas tags, book_tags y en la etapa final utilizamos la tabla books, describiremos brevemente cada tabla.\n",
    "\n",
    "* Ratings: esta tabla contiene todos los ratings de los usuarios.\n",
    "\n",
    "* Tags: esta tabla contiene el id de cada tag y su nombre.\n",
    "\n",
    "* Book Tags: esta tabla contiene los tags asociados a cada libro, es este dataset cada libro tiene 100 tags diferentes.\n",
    "\n",
    "* Books: esta tabla contiene los metadatos del libro, como el nombre, el autor, año de publicación editorial y entre otros, de esta tabla tomamos solamente el nombre para mostrar al final las recomendaciones top para varios usuarios.\n",
    "\n",
    "Dataset sacado de: https://www.kaggle.com/zygmunt/goodbooks-10k\n",
    "\n",
    "Este recomendador fue creado con Spark 2.3.1 con el lenguaje Scala versión 2.12.7 y con el kernel Apache Toree versión 0.3.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 0: Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hacemos un preprocesamiento del dataset para convertir las tablas en data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "books = [id: string, book_id: string ... 21 more fields]\n",
       "book_tags1 = [goodreads_book_id: string, tag_id: string ... 1 more field]\n",
       "book_tags = [book_id: string, tag_id: string ... 1 more field]\n",
       "ratings1 = [book_id: string, user_id: string ... 1 more field]\n",
       "ratings2 = [book_id: int, user_id: int ... 1 more field]\n",
       "rawRatings = [user_id: int, book_id: int ... 1 more field]\n",
       "tags = [tag_id: string, tag_name: string]\n",
       "to_read = [user_id: string, book_id: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: string, book_id: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val books = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"./goodbooks-10k/books.csv\")\n",
    "//books = books.withColumnRenamed(\"id\", \"books_id\")\n",
    "                        \n",
    "val book_tags1 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"goodbooks-10k/book_tags.csv\")\n",
    "val book_tags = book_tags1.withColumnRenamed(\"goodreads_book_id\", \"book_id\")\n",
    "val ratings1 = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"goodbooks-10k/ratings.csv\")\n",
    "val ratings2 = ratings1.withColumn(\"user_id\", $\"user_id\".cast(IntegerType))\n",
    "                        .withColumn(\"book_id\", $\"book_id\".cast(IntegerType))\n",
    "                        .withColumn(\"rating\", $\"rating\".cast(IntegerType))\n",
    "val rawRatings = ratings2.select(\"user_id\", \"book_id\", \"rating\")\n",
    "val tags=spark.read.format(\"csv\").option(\"header\", \"true\").load(\"goodbooks-10k/tags.csv\")\n",
    "val to_read = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"goodbooks-10k/to_read.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro recomendador solo tomaremos las 3 siguientes tablas del dataset. RawRatings quiere decir que nuestros ratings no han sido normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|    314|      1|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+------+------+\n",
      "|book_id|tag_id| count|\n",
      "+-------+------+------+\n",
      "|      1| 30574|167697|\n",
      "+-------+------+------+\n",
      "only showing top 1 row\n",
      "\n",
      "+------+--------+\n",
      "|tag_id|tag_name|\n",
      "+------+--------+\n",
      "|     0|       -|\n",
      "+------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawRatings.show(1)\n",
    "book_tags.show(1)\n",
    "tags.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización\n",
    "\n",
    "Este paso lo debemos aplicar siempre a cada dataset que será usado en el algoritmo ALS.\n",
    "\n",
    "Sea i un usuario, r(i, j) un rating dado al libro j por el usuario i y r_promedio(i) la calificación promedio del usuario i.\n",
    "\n",
    "* rating_normalizado = r(i, j) - r_promedio(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalizeUserRatings: (subject: String, feature: String, df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalizeUserRatings(subject: String, feature: String, df: DataFrame): DataFrame = {\n",
    "    val featureAvg = s\"avg($feature)\"\n",
    "    df.groupBy(subject)\n",
    "        .agg(mean(feature))\n",
    "        .join(df, Seq(subject))\n",
    "        .withColumn(feature, col(feature) - col(featureAvg))\n",
    "        .drop(featureAvg)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi se ven nuestros ratings normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|book_id|              rating|\n",
      "+-------+-------+--------------------+\n",
      "|      1|   1180|  0.3333333333333335|\n",
      "|      1|   4893| -0.6666666666666665|\n",
      "|      1|   6285|  0.3333333333333335|\n",
      "|      2|   8034|-0.33333333333333304|\n",
      "|      2|   8855|   0.666666666666667|\n",
      "|      2|   9762|-0.33333333333333304|\n",
      "|      3|   9014|                 0.0|\n",
      "|      3|   9049|                 0.0|\n",
      "|      4|   3273|                -2.0|\n",
      "|      4|   3469|                 1.0|\n",
      "|      4|   8464|                 1.0|\n",
      "|      5|   4829| -1.2000000000000002|\n",
      "|      5|   6646|-0.20000000000000018|\n",
      "|      5|   6703|-0.20000000000000018|\n",
      "|      5|   7487|  0.7999999999999998|\n",
      "|      5|   8072|  0.7999999999999998|\n",
      "|      6|   7341|                -0.5|\n",
      "|      6|   8033|                 0.5|\n",
      "|      7|    585| 0.23684210526315796|\n",
      "|      7|    910| 0.23684210526315796|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ratings = [user_id: int, book_id: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 1 more field]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratings = normalizeUserRatings(\"user_id\", \"rating\", rawRatings)\n",
    "ratings.orderBy(\"user_id\", \"book_id\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Primeras N recomendaciones\n",
    "\n",
    "Entrenamos nuestro modelo con un bootstrap de 80% para entrenamiento y 20% para validación. En un trabajo futuro se puede usar cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+\n",
      "|user_id|book_id|             rating|\n",
      "+-------+-------+-------------------+\n",
      "|    148|   1453|0.36734693877551017|\n",
      "+-------+-------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "training = [user_id: int, book_id: int ... 1 more field]\n",
       "test = [user_id: int, book_id: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 1 more field]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(training, test) = ratings.randomSplit(Array(0.8, 0.2))\n",
    "training.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos la estrategia drop (eliminar valores nulos) durante la fase de entrenamiento ya que con NaN se puede perder la presición de nuestro sistema, pero cuando se tiene un sistema en producción, debemos utilizar la estrategia NaN, esta nos permite tener recomendaciones por defecto cuando llega un nuevo usuario a nuestro sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------------------+-----------+\n",
      "|user_id|book_id|             rating| prediction|\n",
      "+-------+-------+-------------------+-----------+\n",
      "|      6|   8033|                0.5|0.010072887|\n",
      "|      7|    585|0.23684210526315796|-0.60056484|\n",
      "|      7|    956|  1.236842105263158| 0.76074624|\n",
      "|      7|   1464|  1.236842105263158|  0.7185013|\n",
      "|      7|   1620|  1.236842105263158|  -0.493041|\n",
      "|      7|   1923|0.23684210526315796| 0.17910463|\n",
      "|      7|   2084|  1.236842105263158|  0.4816985|\n",
      "|      7|   2129|  1.236842105263158|   0.681064|\n",
      "|      7|   2491| -2.763157894736842|-0.79667675|\n",
      "|      7|   2693|0.23684210526315796|-0.13145779|\n",
      "|      7|   2766|0.23684210526315796|0.028024688|\n",
      "|      7|   2969|0.23684210526315796|-0.42445216|\n",
      "|      7|   3111|0.23684210526315796|  0.3694944|\n",
      "|      7|   3797| -1.763157894736842|-0.31313896|\n",
      "|      7|   3884| -0.763157894736842| -1.0044386|\n",
      "|      7|   4101| -0.763157894736842|-0.86648285|\n",
      "|      7|   4138| -0.763157894736842|0.049117386|\n",
      "|      7|   4726|0.23684210526315796|-0.08209318|\n",
      "|      7|   4944| -1.763157894736842| 0.33960307|\n",
      "|      7|   5047|0.23684210526315796| -0.7583602|\n",
      "+-------+-------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "als = als_3bc6da3eb8e1\n",
       "alsModel = als_3bc6da3eb8e1\n",
       "predictions = [user_id: int, book_id: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 2 more fields]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val als = new ALS()\n",
    "    .setMaxIter(5)\n",
    "    .setRegParam(0.01)\n",
    "    .setUserCol(\"user_id\")\n",
    "    .setItemCol(\"book_id\")\n",
    "    .setRatingCol(\"rating\")\n",
    "//println(als.explainParams())\n",
    "val alsModel = als.fit(training)\n",
    "alsModel.setColdStartStrategy(\"drop\")\n",
    "val predictions = alsModel.transform(test)\n",
    "predictions.orderBy(\"user_id\", \"book_id\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos conocer las recomendaciones top para cada usuario. La instrucción recommendForAllUsers retorna un data frame con array de recomendaciones para cada usuario representado por userId y también el rating de cada libro, recommendForAllItems en cambio, retorna el mismo dataframe, pero con un array del top de usuarios para ese libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|user_id|              col|\n",
      "+-------+-----------------+\n",
      "|    148| [1400, 1.466075]|\n",
      "|    148|  [52, 1.4550807]|\n",
      "|    148|[6634, 1.4195163]|\n",
      "|    148|[1188, 1.3356676]|\n",
      "|    148|[6546, 1.3179394]|\n",
      "|    148|  [39, 1.2452117]|\n",
      "|    148|[4283, 1.2375112]|\n",
      "|    148|[2259, 1.2112757]|\n",
      "|    148| [2717, 1.191325]|\n",
      "|    148|[3949, 1.1849052]|\n",
      "|    148|[1703, 1.1716278]|\n",
      "|    148|[1532, 1.1596256]|\n",
      "|    148| [350, 1.1317966]|\n",
      "|    148|  [49, 1.1239188]|\n",
      "|    148| [4267, 1.119725]|\n",
      "|    148|[2122, 1.1184484]|\n",
      "|    148|[1847, 1.1165259]|\n",
      "|    148|[4195, 1.1140817]|\n",
      "|    148|[8141, 1.1123798]|\n",
      "|    148|[1638, 1.1012355]|\n",
      "+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+------------------+\n",
      "|book_id|               col|\n",
      "+-------+------------------+\n",
      "|   1580|[45764, 2.0233183]|\n",
      "|   1580|[51381, 2.0078063]|\n",
      "|   1580| [5928, 1.9380112]|\n",
      "|   1580| [9442, 1.8996718]|\n",
      "|   1580|[45050, 1.8908777]|\n",
      "|   1580|[50827, 1.8440964]|\n",
      "|   1580|[25066, 1.8284339]|\n",
      "|   1580|[17544, 1.8216096]|\n",
      "|   1580|[30585, 1.8170512]|\n",
      "|   1580|[13093, 1.7797055]|\n",
      "|   1580|[13132, 1.7692585]|\n",
      "|   1580|[21549, 1.7569818]|\n",
      "|   1580| [32480, 1.747597]|\n",
      "|   1580| [2338, 1.7272549]|\n",
      "|   1580| [7405, 1.7228056]|\n",
      "|   1580|[37621, 1.7156845]|\n",
      "|   1580|[33572, 1.7156117]|\n",
      "|   1580|[17802, 1.7152061]|\n",
      "|   1580|[52221, 1.7072891]|\n",
      "|   1580|[43551, 1.6882166]|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userRecs = [user_id: int, col: struct<book_id: int, rating: float>]\n",
       "itemRecommendations = [book_id: int, col: struct<user_id: int, rating: float>]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[book_id: int, col: struct<user_id: int, rating: float>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userRecs = alsModel.recommendForAllUsers(30)\n",
    "    .selectExpr(\"user_id\", \"explode(recommendations)\")\n",
    "val itemRecommendations = alsModel.recommendForAllItems(30)\n",
    "    .selectExpr(\"book_id\", \"explode(recommendations)\")\n",
    "\n",
    "userRecs.show(20)\n",
    "itemRecommendations.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Ratings pesados por tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarmamos el array del dataframe anterior para poder manipular mas fácilmente los datos. Estos nuevos ratings corresponden a las N recomendaciones para cada usuario i, lo siguiente es añadirle el peso del tag a cada rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+\n",
      "|user_id|book_id|   rating|\n",
      "+-------+-------+---------+\n",
      "|    148|   1400| 1.466075|\n",
      "|    148|     52|1.4550807|\n",
      "|    148|   6634|1.4195163|\n",
      "|    148|   1188|1.3356676|\n",
      "|    148|   6546|1.3179394|\n",
      "|    148|     39|1.2452117|\n",
      "|    148|   4283|1.2375112|\n",
      "|    148|   2259|1.2112757|\n",
      "|    148|   2717| 1.191325|\n",
      "|    148|   3949|1.1849052|\n",
      "|    148|   1703|1.1716278|\n",
      "|    148|   1532|1.1596256|\n",
      "|    148|    350|1.1317966|\n",
      "|    148|     49|1.1239188|\n",
      "|    148|   4267| 1.119725|\n",
      "|    148|   2122|1.1184484|\n",
      "|    148|   1847|1.1165259|\n",
      "|    148|   4195|1.1140817|\n",
      "|    148|   8141|1.1123798|\n",
      "|    148|   1638|1.1012355|\n",
      "+-------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userTop = [user_id: int, book_id: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 1 more field]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userTop = userRecs.withColumn(\"book_id\", $\"col.book_id\")\n",
    "    .withColumn(\"rating\", $\"col.rating\")\n",
    "    .drop($\"col\")\n",
    "userTop.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un cruce de los libros con sus repectivos tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Agregar el tag a cada recomendación, debemos hacer un join con la tabla book_tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+------+\n",
      "|book_id|user_id|   rating|tag_id|\n",
      "+-------+-------+---------+------+\n",
      "|   2122|    148|1.1184484| 30574|\n",
      "|   2122|    148|1.1184484|  8717|\n",
      "|   2122|    148|1.1184484| 11743|\n",
      "|   2122|    148|1.1184484|  7457|\n",
      "|   2122|    148|1.1184484| 11557|\n",
      "|   2122|    148|1.1184484| 23471|\n",
      "|   2122|    148|1.1184484| 22743|\n",
      "|   2122|    148|1.1184484| 18367|\n",
      "|   2122|    148|1.1184484|  7404|\n",
      "|   2122|    148|1.1184484|  5207|\n",
      "|   2122|    148|1.1184484| 22034|\n",
      "|   2122|    148|1.1184484|  2867|\n",
      "|   2122|    148|1.1184484| 26256|\n",
      "|   2122|    148|1.1184484| 23931|\n",
      "|   2122|    148|1.1184484|  3704|\n",
      "|   2122|    148|1.1184484| 22753|\n",
      "|   2122|    148|1.1184484| 11590|\n",
      "|   2122|    148|1.1184484| 30521|\n",
      "|   2122|    148|1.1184484| 21989|\n",
      "|   2122|    148|1.1184484|  9221|\n",
      "|   2122|    148|1.1184484| 12948|\n",
      "|   2122|    148|1.1184484| 18045|\n",
      "|   2122|    148|1.1184484|  2277|\n",
      "|   2122|    148|1.1184484|  1416|\n",
      "|   2122|    148|1.1184484| 22159|\n",
      "|   2122|    148|1.1184484| 18326|\n",
      "|   2122|    148|1.1184484|  2104|\n",
      "|   2122|    148|1.1184484|  1642|\n",
      "|   2122|    148|1.1184484| 20849|\n",
      "|   2122|    148|1.1184484|  7423|\n",
      "|   2122|    148|1.1184484|  1659|\n",
      "|   2122|    148|1.1184484| 26251|\n",
      "|   2122|    148|1.1184484| 27535|\n",
      "|   2122|    148|1.1184484| 23909|\n",
      "|   2122|    148|1.1184484|  2313|\n",
      "|   2122|    148|1.1184484| 20774|\n",
      "|   2122|    148|1.1184484|  3389|\n",
      "|   2122|    148|1.1184484| 18318|\n",
      "|   2122|    148|1.1184484|   923|\n",
      "|   2122|    148|1.1184484| 26246|\n",
      "|   2122|    148|1.1184484|  4949|\n",
      "|   2122|    148|1.1184484| 20282|\n",
      "|   2122|    148|1.1184484| 31505|\n",
      "|   2122|    148|1.1184484|  7478|\n",
      "|   2122|    148|1.1184484| 17213|\n",
      "|   2122|    148|1.1184484| 11505|\n",
      "|   2122|    148|1.1184484|  8055|\n",
      "|   2122|    148|1.1184484|  9477|\n",
      "|   2122|    148|1.1184484| 24960|\n",
      "|   2122|    148|1.1184484| 24883|\n",
      "|   2122|    148|1.1184484| 15169|\n",
      "|   2122|    148|1.1184484| 23465|\n",
      "|   2122|    148|1.1184484| 13207|\n",
      "|   2122|    148|1.1184484| 32586|\n",
      "|   2122|    148|1.1184484| 15500|\n",
      "|   2122|    148|1.1184484| 26257|\n",
      "|   2122|    148|1.1184484| 11497|\n",
      "|   2122|    148|1.1184484| 14370|\n",
      "|   2122|    148|1.1184484| 26138|\n",
      "|   2122|    148|1.1184484|  3392|\n",
      "|   2122|    148|1.1184484| 30635|\n",
      "|   2122|    148|1.1184484|  3358|\n",
      "|   2122|    148|1.1184484| 10064|\n",
      "|   2122|    148|1.1184484|  7417|\n",
      "|   2122|    148|1.1184484| 26735|\n",
      "|   2122|    148|1.1184484| 10245|\n",
      "|   2122|    148|1.1184484| 22689|\n",
      "|   2122|    148|1.1184484| 30573|\n",
      "|   2122|    148|1.1184484| 10197|\n",
      "|   2122|    148|1.1184484| 30672|\n",
      "|   2122|    148|1.1184484| 20731|\n",
      "|   2122|    148|1.1184484| 10644|\n",
      "|   2122|    148|1.1184484| 26837|\n",
      "|   2122|    148|1.1184484|  9886|\n",
      "|   2122|    148|1.1184484|  2312|\n",
      "|   2122|    148|1.1184484|  3371|\n",
      "|   2122|    148|1.1184484|  6235|\n",
      "|   2122|    148|1.1184484| 10210|\n",
      "|   2122|    148|1.1184484|  5951|\n",
      "|   2122|    148|1.1184484| 21689|\n",
      "|   2122|    148|1.1184484| 11798|\n",
      "|   2122|    148|1.1184484|  3703|\n",
      "|   2122|    148|1.1184484| 14064|\n",
      "|   2122|    148|1.1184484| 12940|\n",
      "|   2122|    148|1.1184484| 10059|\n",
      "|   2122|    148|1.1184484| 25011|\n",
      "|   2122|    148|1.1184484| 14487|\n",
      "|   2122|    148|1.1184484|  9484|\n",
      "|   2122|    148|1.1184484| 21374|\n",
      "|   2122|    148|1.1184484|  8067|\n",
      "|   2122|    148|1.1184484| 22330|\n",
      "|   2122|    148|1.1184484|  7422|\n",
      "|   2122|    148|1.1184484| 23349|\n",
      "|   2122|    148|1.1184484| 20288|\n",
      "|   2122|    148|1.1184484| 18292|\n",
      "|   2122|    148|1.1184484| 25506|\n",
      "|   2122|    148|1.1184484| 11644|\n",
      "|   2122|    148|1.1184484| 20824|\n",
      "|   2122|    148|1.1184484|  9638|\n",
      "|   2122|    148|1.1184484|   430|\n",
      "|   2122|  18498|2.7793448| 30574|\n",
      "+-------+-------+---------+------+\n",
      "only showing top 101 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "userBookTags = [book_id: int, user_id: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[book_id: int, user_id: int ... 2 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val userBookTags = userTop.join(book_tags, Seq(\"book_id\")).drop(\"count\")\n",
    "userBookTags.show(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una nueva relación, la cual contiene el rating de cada usuario i, para algunos tags k, porque no todos los usuarios han calificado libros con cada uno de los tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+\n",
      "|user_id|tag_id|        tag_rating|\n",
      "+-------+------+------------------+\n",
      "|    148| 10059|1.1251224875450134|\n",
      "|    148|  9638|1.1251224875450134|\n",
      "|  18498|  1659|2.8725833892822266|\n",
      "|  30320| 14370|1.5823676586151123|\n",
      "|  30320|  7422|1.7068182826042175|\n",
      "|    731| 22330| 4.746710538864136|\n",
      "|   7634| 11644|  1.79701566696167|\n",
      "|  20054| 20731|3.3154056072235107|\n",
      "|   9147|  9477|2.0902416706085205|\n",
      "|  11823| 20288|2.1110766530036926|\n",
      "|  40759|  2867|0.8579235672950745|\n",
      "|  51944|  8067|1.4814887046813965|\n",
      "|  26226| 26735|0.4439089596271515|\n",
      "|  16469| 22753| 1.113128900527954|\n",
      "|  16469| 18326| 1.113128900527954|\n",
      "|  12708|  4949|2.4273698329925537|\n",
      "|  12708| 10644| 2.401083564758301|\n",
      "|  21319| 20731| 0.784599781036377|\n",
      "|  12972| 23465|1.6162128448486328|\n",
      "|  36789| 11798|1.5498590469360352|\n",
      "+-------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "topTags = [user_id: int, tag_id: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, tag_id: string ... 1 more field]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val topTags = userBookTags.groupBy(\"user_id\", \"tag_id\")\n",
    "                        .agg(mean(\"rating\"))\n",
    "                        .withColumnRenamed(\"avg(rating)\", \"tag_rating\")\n",
    "topTags.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos hasta ahora, un rating de usarios para libros y otro para tags, lo siguiente es sumar ambos ratings, para crear los ratings pesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|user_id|book_id|            rating|\n",
      "+-------+-------+------------------+\n",
      "|     63|   8960|2.2188713550567627|\n",
      "|    133|    656| 7.914589285850525|\n",
      "|    202|   6748| 3.547788143157959|\n",
      "|    217|   3109| 4.188754081726074|\n",
      "|    367|   7714| 4.756189823150635|\n",
      "|    577|   9375|3.8534820874532065|\n",
      "|    762|   5553| 2.784930646419525|\n",
      "|    958|      8|3.2475767731666565|\n",
      "|   1006|    350| 6.521520972251892|\n",
      "|   1150|    250|               0.0|\n",
      "|   1190|      3| 8.855115175247192|\n",
      "|   1215|    231|               0.0|\n",
      "|   1477|   4820|2.5996833244959516|\n",
      "|   1849|   2050| 3.449760675430298|\n",
      "|   1854|     30|               0.0|\n",
      "|   1917|   1319|1.2657529364029565|\n",
      "|   2028|     30|               0.0|\n",
      "|   2135|     30|               0.0|\n",
      "|   2179|     10|               0.0|\n",
      "|   2300|   1842|5.6391730308532715|\n",
      "+-------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "weightedRecs = [user_id: int, book_id: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 1 more field]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val weightedRecs = userBookTags.join(topTags, Seq(\"user_id\", \"tag_id\"))\n",
    "                            .withColumn(\"rating\", $\"rating\" + $\"tag_rating\")\n",
    "                            .drop(\"tag_rating\")\n",
    "                            .drop(\"tag_id\")\n",
    "                            .distinct()\n",
    "weightedRecs.orderBy($\"user_id\", $\"rating\".desc).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3: Recomendación con ratings pesados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a normalizar el rating combinado antes de ejecutar nuevamente el algorimo ALS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|book_id|              rating|\n",
      "+-------+-------+--------------------+\n",
      "|      1|   4008| 0.14036134878794349|\n",
      "|      1|   9503|-0.02337874223788583|\n",
      "|      1|   1110|-0.11698260655005777|\n",
      "|      2|   5348| 0.09841588139533997|\n",
      "|      2|   1934|-0.09841588139533997|\n",
      "|      3|     30|                 0.0|\n",
      "|      3|    250|                 0.0|\n",
      "|      3|     10|                 0.0|\n",
      "|      3|     50|                 0.0|\n",
      "|      4|   4261| 0.49617784221967076|\n",
      "|      4|   7214| -0.1891876856486001|\n",
      "|      4|   9717| -0.3069901565710702|\n",
      "|      5|   1934|  0.2903935622366379|\n",
      "|      5|   4009| 0.16281201251817576|\n",
      "|      5|     11|-0.03631577786945237|\n",
      "|      5|   7058|-0.06756042538857047|\n",
      "|      5|     67| -0.0777545711266729|\n",
      "|      5|   9595| -0.1150482391451008|\n",
      "|      5|   4633|-0.15286303504637747|\n",
      "|      6|   3885| 0.10404811799526215|\n",
      "|      6|   5355|-0.10404811799526215|\n",
      "|      7|   1934|                 0.0|\n",
      "|      8|   5553| 0.38112222154935216|\n",
      "|      8|     34|-0.18606318036715175|\n",
      "|      8|     27|-0.19505904118219997|\n",
      "|      9|   6420|  0.1101146936416626|\n",
      "|      9|   9809| -0.1101146936416626|\n",
      "|     10|   4530|  0.5037473340829215|\n",
      "|     10|   2715|  0.3306387265523276|\n",
      "|     10|   5175| -0.8343860606352487|\n",
      "|     11|   5175| 0.19925614095282265|\n",
      "|     11|    998|-0.04182223581719687|\n",
      "|     11|   8921|-0.04884412118244463|\n",
      "|     11|   6748|-0.10161205235568975|\n",
      "|     13|     10|                 0.0|\n",
      "|     13|    250|                 0.0|\n",
      "|     13|     30|                 0.0|\n",
      "|     13|     50|                 0.0|\n",
      "|     14|    816| 0.04307779669761658|\n",
      "|     14|   7742|-0.04307779669761658|\n",
      "|     15|   7194|0.053451865911483765|\n",
      "|     15|   5872|-0.05345186591148...|\n",
      "|     16|   2623|  0.1689380378950211|\n",
      "|     16|   7980|-0.02578212420145...|\n",
      "|     16|   5038|-0.07271106186367206|\n",
      "|     16|   2715|-0.10893564224243155|\n",
      "|     17|     10|                 0.0|\n",
      "|     17|     50|                 0.0|\n",
      "|     17|    250|                 0.0|\n",
      "|     17|     30|                 0.0|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "normRecs = [user_id: int, book_id: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 1 more field]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val normRecs = normalizeUserRatings(\"user_id\", \"rating\", weightedRecs)\n",
    "//                         .groupBy(\"user_id\", \"book_id\")\n",
    "//                         .agg(mean(\"rating\"))\n",
    "//                         .withColumnRenamed(\"avg(rating)\", \"rating\")\n",
    "normRecs.orderBy($\"user_id\", $\"rating\".desc).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente se hizo el entrenamiento paso a paso, pero esta vez simplificamos el entrenamiento a una función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "makeRecommender: (ratings: org.apache.spark.sql.DataFrame)org.apache.spark.ml.recommendation.ALSModel\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def makeRecommender(ratings: DataFrame): ALSModel = {\n",
    "    val Array(training, test) = ratings.randomSplit(Array(0.8, 0.2))\n",
    "    val als = new ALS()\n",
    "        .setMaxIter(5)\n",
    "        .setRegParam(0.01)\n",
    "        .setUserCol(\"user_id\")\n",
    "        .setItemCol(\"book_id\")\n",
    "        .setRatingCol(\"rating\")\n",
    "    val alsModel = als.fit(training)\n",
    "    \n",
    "    alsModel.setColdStartStrategy(\"drop\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos nuestro recomendador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommender = als_ecb8c7e21286\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "als_ecb8c7e21286"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val recommender = makeRecommender(normRecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getRecommendations: (alsModel: org.apache.spark.ml.recommendation.ALSModel, numRecs: Int)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getRecommendations(alsModel: ALSModel, numRecs: Int): DataFrame = {\n",
    "    val userRecs = alsModel.recommendForAllUsers(numRecs)\n",
    "        .selectExpr(\"user_id\", \"explode(recommendations)\")\n",
    "    \n",
    "    val userTop = userRecs.withColumn(\"book_id\", $\"col.book_id\")\n",
    "    .withColumn(\"rating\", $\"col.rating\")\n",
    "    .drop($\"col\")\n",
    "    \n",
    "    userTop\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamamos ahora las 10 recomendaciones top para cada uno de los usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recommendations = [user_id: int, book_id: int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 1 more field]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val recommendations = getRecommendations(recommender, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos nuestras recomendaciones en nuestro sistema de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommendations.write.format(\"csv\").save(\"./recommendations_by_tags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente hacemos un join con la tabla libros, para conocer los nombres de los 10 libros top para algunos usuarios. Se puede ver que para algunos usuarios aparecen libros en otros idiomas, por lo cual seria nescesario agregar los idiomas como un nuevo parametro para nuestro recomendador en un futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-------+-----------+\n",
      "|      original_title|user_id|book_id|     rating|\n",
      "+--------------------+-------+-------+-----------+\n",
      "|O Demônio e a Srt...|      1|   4008| 0.12814066|\n",
      "|    The Book of Ruth|      1|   5187|  0.1268632|\n",
      "|  Benim Adım Kırmızı|      1|   2517| 0.11231489|\n",
      "|Harry Potter and ...|      1|      3| 0.10356098|\n",
      "|          Microserfs|      1|   2748|0.102506824|\n",
      "|                Emma|      1|   6969| 0.08818711|\n",
      "|Twelfth Night; or...|      1|   1625| 0.08596574|\n",
      "|      BLEACH―ブリーチ―　1|      1|   2880| 0.08452353|\n",
      "|Visions of Sugar ...|      1|   6420| 0.08434392|\n",
      "|By the Shores of ...|      1|   8248| 0.07831517|\n",
      "|Killers of the Da...|      2|   8952| 0.13937993|\n",
      "|象の消滅 [Zō no shōme...|      2|   9555| 0.10568179|\n",
      "|       The Testament|      2|   5348| 0.09179212|\n",
      "|  A Map of the World|      2|   5205| 0.09175916|\n",
      "|      The Amber Room|      2|   5369| 0.07434282|\n",
      "|              Anthem|      2|    667|0.074233696|\n",
      "|Unfinished Tales ...|      2|   7329|0.069240615|\n",
      "|O Demônio e a Srt...|      2|   4008| 0.06311008|\n",
      "|  Benim Adım Kırmızı|      2|   2517|0.062480874|\n",
      "|The Ultimate Hitc...|      2|     13|0.060690224|\n",
      "|            鋼の錬金術師 1|      3|    870|        0.0|\n",
      "|Stranger in a Str...|      3|    350|        0.0|\n",
      "|     Mostly Harmless|      3|    360|        0.0|\n",
      "| Tropic of Capricorn|      3|    250|        0.0|\n",
      "|             Hatchet|      3|     50|        0.0|\n",
      "|          Snow Crash|      3|    830|        0.0|\n",
      "|The Hobbit and Th...|      3|     30|        0.0|\n",
      "|Memoria de mis pu...|      3|    760|        0.0|\n",
      "|Cien años de soledad|      3|    320|        0.0|\n",
      "|Harry Potter Coll...|      3|     10|        0.0|\n",
      "|象の消滅 [Zō no shōme...|      4|   9555| 0.44884932|\n",
      "|            31 Songs|      4|   4261|  0.4484123|\n",
      "|Confessions of a ...|      4|   9416| 0.40997666|\n",
      "|  Eaters of the Dead|      4|   7673| 0.40847158|\n",
      "|Killers of the Da...|      4|   8952|  0.3991879|\n",
      "|Eats, Shoots and ...|      4|   8600| 0.39874476|\n",
      "|The Lost Continen...|      4|     26|  0.3971235|\n",
      "|          Goldfinger|      4|   3759|  0.3971027|\n",
      "|         The Witches|      4|   6327|  0.3903045|\n",
      "|A Christmas Carol...|      4|   5338| 0.37872753|\n",
      "+--------------------+-------+-------+-----------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "recs = [original_title: string, user_id: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[original_title: string, user_id: int ... 2 more fields]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val recs = recommendations.join(books, Seq(\"book_id\"))\n",
    "                        .select(\"original_title\", \"user_id\", \"book_id\", \"rating\")\n",
    "                        .orderBy($\"user_id\", $\"rating\".desc)\n",
    "recs.show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "Ahora debemos evaluar el desempeño de nuestro modelo. En este caso utilizaremos métricas de ranking, para saber si nuestro modelo es capaz de recomendar un libro que previamente ha sido bien calificado por el usuario.\n",
    "\n",
    "Note que los ratings en el data frame *predictions* que obtuvimos de la primera etapa, son los ratings reales de nuestro dataset, en el frame *predictions*, la prediciones estan en otra columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n",
       "evaluate: (predictions: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.{RankingMetrics, RegressionMetrics}\n",
    "import org.apache.spark.sql.functions.{col, expr}\n",
    "\n",
    "def evaluate(predictions: DataFrame, tag_predictions: DataFrame): Unit = {\n",
    "    val perUserActual = predictions\n",
    "        .where(\"rating > 2.5\")\n",
    "        .groupBy(\"user_id\")\n",
    "        .agg(expr(\"collect_set(book_id) as books\"))\n",
    "\n",
    "    val perUserPredictions = predictions\n",
    "        .orderBy(col(\"user_id\"), col(\"prediction\").desc)\n",
    "        .groupBy(\"user_id\")\n",
    "        .agg(expr(\"collect_list(book_id) as books\"))\n",
    "\n",
    "    val perUserActualvPred = perUserActual.join(perUserPredictions, Seq(\"user_id\"))\n",
    "        .map(row => (\n",
    "        row(1).asInstanceOf[Seq[Integer]].toArray,\n",
    "        row(2).asInstanceOf[Seq[Integer]].toArray.take(15)\n",
    "        ))\n",
    "    val ranks = new RankingMetrics(perUserActualvPred.rdd)\n",
    "\n",
    "    println(s\"Mean average Precision = ${ranks.meanAveragePrecision}\")\n",
    "    Seq(1, 3, 5, 8, 10).foreach( k =>\n",
    "        println(s\"Precision at k: $k = ${ranks.precisionAt(k)}\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rootMeanSquareError: (predictions: org.apache.spark.sql.DataFrame)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    " \n",
    "def rootMeanSquareError(predictions: DataFrame): Unit = {\n",
    "    val evaluator = new RegressionEvaluator()\n",
    "        .setMetricName(\"rmse\")\n",
    "        .setLabelCol(\"rating\")\n",
    "        .setPredictionCol(\"prediction\")\n",
    "    val rmse = evaluator.evaluate(predictions)\n",
    "    println(s\"Root-mean-square error = $rmse\")\n",
    "    print(\"Global average RMSE = 1.1296, netflix grand prize = 0.8563\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro caso nuestro recomendador acierta bn en la primera predicción, pero apartir de ahi su desempeño cae bastante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average Precision = 1.0\n",
      "Precision at k: 1 = 1.0\n",
      "Precision at k: 3 = 0.3333333333333333\n",
      "Precision at k: 5 = 0.2\n",
      "Precision at k: 8 = 0.125\n",
      "Precision at k: 10 = 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag_predictions = [user_id: int, book_id: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: int, book_id: int ... 2 more fields]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tag_predictions = recommender.transform(test)\n",
    "evaluate(predictions, tag_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuando al error cuadrático medio, obtenemos un buen puntaje ya que nuestros ratings ponderados se aproximan el valor del rating real que el usuario ha dado a los libros que le hemos recomendado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8971356910900724\n",
      "Global average RMSE = 1.1296, netflix grand prize = 0.8563"
     ]
    }
   ],
   "source": [
    "rootMeanSquareError(tag_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "Nuestro recomendador es bueno prediciendo ratings, pero aun le falta trabajo para hacer buenas recomendaciones, para lo cual debemos probar con mas metadatos y nuevos algoritmos para llegar a una soloción mas óptima."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
